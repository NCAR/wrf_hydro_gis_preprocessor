{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Source GIS Pre-Processing Tutorial\n",
    "\n",
    "This notebook will rely on the WRF-Hydro GIS Pre-processing tools, found here:  \n",
    "* https://github.com/NCAR/wrf_hydro_gis_preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Create domain boundary shapefile](#1.-Create-domain-boundary-shapefile)<br>\n",
    "2. [Build geotiff from geogrid file](#2.-Build-GeoTiff-raster-from-a-WPS-Geogrid-file)<br>\n",
    "3. [Build routing stack](#3.-Building-the-hydrologic-routing-grids,-aka-the-\"routing-stack\")<br>\n",
    "4. [Examine outputs of GIS pre-processor](#4.-Examine-outputs-of-GIS-pre-processor)\n",
    "5. [Vizualize the output grids](#5.-Vizualize-the-output-grids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, set file paths\n",
    "In this cell, Python variables are created that point to the file paths of the test-case data and an output directory is defined to store the data created by these tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import python core modules\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set root directory for GIS lesson\n",
    "gis_data_folder = \"/home/docker/GIS_Training\"\n",
    "\n",
    "# Change the directory to the GIS_Training directory and get current working directory\n",
    "os.chdir(gis_data_folder)\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Set paths to known input and output directories and files\n",
    "data_folder = os.path.join(cwd, 'Croton_Lambert')\n",
    "in_geogrid = os.path.join(data_folder, 'geo_em.d01.nc')\n",
    "output_folder = os.path.join(cwd, 'Outputs')\n",
    "\n",
    "# Clear any outputs from previous runs\n",
    "if os.path.exists(output_folder):\n",
    "    shutil.rmtree(output_folder)\n",
    "    os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create domain boundary shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The tool `Create_Domain_Boundary_Shapefile.py` takes a WRF (WPS) output file, aka \"Geogrid file\", and creates a polygon shapefile that defines the boundary of the domain as a single rectangular polygon in projected coordinates. The script will read metadata in the geogrid file and the output shapefile will be in the projection of the WRF domain. The unstaggered grid, or \"Mass\" grid (e.g. \"HGT_M\" variable), is used as the routing grid domain by WRF-Hydro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request help message from the script\n",
    "This is an example of the syntax for calling the `Create_Domain_Boundary_Shapefile.py` tool on the command line. By following the tool with `-h` or `--help`, we are able to call the help arguement which explains the purpose of the tool, shows the different arguements we can use for this tool, as well as the descriptions for each arguement. \n",
    "\n",
    "When the tool is run in the terminal, it is not necessary to use the exclamation point. In Jupyter Notebook, we can execute command-line syntax using \"!\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script initiated at Sun Nov  1 14:38:30 2020\n",
      "usage: Create_Domain_Boundary_Shapefile.py [-h] -i IN_NC -o OUT_DIR\n",
      "\n",
      "This tool takes an WRF Geogrid file and creates a single polygon shapefile\n",
      "that makes up the boundary of the domain of the M-grid (HGT_M, for example).\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help  show this help message and exit\n",
      "  -i IN_NC    Path to WPS geogrid (geo_em.d0*.nc) file or WRF-Hydro\n",
      "              Fulldom_hires.nc file.\n",
      "  -o OUT_DIR  Output directory.\n"
     ]
    }
   ],
   "source": [
    "import Create_Domain_Boundary_Shapefile\n",
    "\n",
    "# Execute script on the command-line, requesting tool help (parameter -h)\n",
    "! python Create_Domain_Boundary_Shapefile.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "You will see in the messages above that the tool provides a brief explanation of the expected input and output parameters. This tool requires a geogrid file as input (`-i`) and a directory to write the outputs into (`-o`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Execute the script using command-line syntax\n",
    "Now that we know what arguements are needed for this tool, we can enter those arguements and run the tool. For this script, we only need to specify the file path to the WPS geogrid file and an output folder to save the result. The result of this tool is a shapefile that shows the geographic boundary of the domain, as defined in the input geogrid file. \n",
    "\n",
    "When running this tool in Jupyter, we can use brackets around our variable names, and Jupyter will substitute the variable values when executing the syntax. However, when exeuting this script on the command line it is necessary to use the appropriate text. For the sake of repeatability, we also have Python print the full syntax for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command to run:\n",
      "\n",
      "python Create_Domain_Boundary_Shapefile.py \\\n",
      "\t -i /home/docker/GIS_Training/Croton_Lambert/geo_em.d01.nc \\\n",
      "\t -o /home/docker/GIS_Training/Outputs\n",
      "\n",
      "Script initiated at Sun Nov  1 14:38:31 2020\n",
      "WPS netCDF projection identification initiated...\n",
      "    Map Projection: Lambert Conformal Conic\n",
      "    Using MOAD_CEN_LAT for latitude of origin.\n",
      "    Using Standard Parallel 2 in Lambert Conformal Conic map projection.\n",
      "    Geo-referencing step completed without error in  0.05 seconds.\n",
      "    Created projection definition from input NetCDF GEOGRID file.\n",
      "      ESRI Shapefile driver is available.\n",
      "  Done producing output vector polygon shapefile in  0.00 seconds\n",
      "  Output shapefile: /home/docker/GIS_Training/Outputs/geo_em.d01_boundary.shp\n",
      "Process completed in 0.07 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Print information to screen for reference\n",
    "print('Command to run:\\n')\n",
    "print('python Create_Domain_Boundary_Shapefile.py \\\\\\n\\t -i {0} \\\\\\n\\t -o {1}\\n'.format(in_geogrid, output_folder))\n",
    "\n",
    "# Run the script with required parameters\n",
    "! python Create_Domain_Boundary_Shapefile.py -i {in_geogrid} -o {output_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "----\n",
    "The messages returned by the tool can be quite useful. You will see the coordinate system information printed to the screen and progress messages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the domain boundary shapefile created in the above example\n",
    "\n",
    "Now that the domain boundary shapefile has been created, we want to see where the domain is relative to other features on a map. The next cell creates a map and adds the domain boundary as a layer. Use the map to explore the domain. A swipe feature allows the basemap to be changed between OpenStreetMap and satellite imagery. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad0cb085130459e99c233c3d57552e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[41.47099335461109, -73.74365046255139], controls=(ZoomControl(options=['position', 'zoom_in_text',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import geopandas\n",
    "from ipyleaflet import Map, GeoJSON, ScaleControl, FullScreenControl, basemaps, SplitMapControl, basemap_to_tiles, LayersControl\n",
    "from jupyter_functions import create_map\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Setup display items\n",
    "boundary_shp = os.path.join(output_folder,'geo_em.d01_boundary.shp')\n",
    "b_shp = geopandas.read_file(boundary_shp)\n",
    "b_shp = b_shp.to_crs(epsg=4326)\n",
    "\n",
    "# Export vector to GeoJSON\n",
    "b_json = os.path.join(output_folder, 'boundary.json')\n",
    "b_shp.to_file(b_json, driver='GeoJSON')\n",
    "\n",
    "# Read GeoJSON\n",
    "with open(b_json, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "# Obtain vector center point\n",
    "x = b_shp.geometry.centroid.x\n",
    "y = b_shp.geometry.centroid.y\n",
    "map_center = y[0], x[0]\n",
    "\n",
    "# Instantiate map object\n",
    "m = Map(center=(41.50, -73.73), zoom=10, scroll_wheel_zoom=True)\n",
    "\n",
    "# Read GeoJSON\n",
    "with open(b_json, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Obtain vector center point\n",
    "x = b_shp.geometry.centroid.x\n",
    "y = b_shp.geometry.centroid.y\n",
    "map_center = y[0], x[0]\n",
    "\n",
    "# Instantiate map object\n",
    "m = create_map(map_center, 10)\n",
    "\n",
    "# Read GeoJSON\n",
    "geo_json = GeoJSON(data=data, name='Domain boundary')\n",
    "\n",
    "# Define basemaps to swipe between\n",
    "right_layer = basemap_to_tiles(basemap=basemaps.OpenStreetMap.Mapnik)\n",
    "left_layer = basemap_to_tiles(basemap=basemaps.Esri.WorldImagery)\n",
    "\n",
    "# Setup basemap swipe control\n",
    "control = SplitMapControl(left_layer=left_layer, right_layer=right_layer)\n",
    "m.add_control(control)\n",
    "m.add_layer(geo_json)\n",
    "\n",
    "# Draw map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build GeoTiff raster from a WPS Geogrid file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The tool `Build_GeoTiff_From_Geogrid_File.py` is a program to export variables from a WRF-Hydro input file (geogrid or Fulldom_hires) file to an output raster format, with all spatial and coordinate system metadata. If a 3-dimensional variable is selected, individual raster bands will be created in the output raster for each index in the 3rd dimension. If a 4-dimensional variable is selected, the first index in the 4th dimension will be selected and the variable will be treated as a 3-dimensional variable described above.\n",
    "\n",
    "This tool is handy for performing a quick vizualization using GIS or othe software to examine the contents of the WRF-Hydro input file and overlay these grids with other goespatial data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tool takes three input parameters: an input Geogrid or Fulldom_hires netCDF file (`-i`), a variable name (`-v`), and an output GeoTiff raster file (`-o`) that the tool will create. For this example, we will export the variable \"HGT_M\", or surface elevation in meters above sea level.\n",
    "\n",
    "#### Request help message from the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script initiated at Sun Nov  1 14:38:34 2020\n",
      "usage: Build_GeoTiff_From_Geogrid_File.py [-h] -i IN_NC [-v VARIABLE]\n",
      "                                          [-o OUT_FILE]\n",
      "\n",
      "This is a program to export >=2D variables from a WRF-Hydro input file\n",
      "(geogrid or Fulldom_hires) file to an output raster format, with all spatial\n",
      "and coordinate system metadata. If a 3-dimensional variable is selected,\n",
      "individual raster bands will be created in the output raster for each index in\n",
      "the 3rd dimension. If a 4-dimensional variable is selected, the first index in\n",
      "the 4th dimension will be selected and the variable will be treated as a\n",
      "3-dimensional variable described above.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help   show this help message and exit\n",
      "  -i IN_NC     Path to WPS geogrid (geo_em.d0*.nc) file or WRF-Hydro\n",
      "               Fulldom_hires.nc file.\n",
      "  -v VARIABLE  Name of the variable in the input netCDF file. default=HGT_M\n",
      "  -o OUT_FILE  Output GeoTiff raster file.\n"
     ]
    }
   ],
   "source": [
    "# Get script help information\n",
    "! python Build_GeoTiff_From_Geogrid_File.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "----\n",
    "#### Execute the script using command-line syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command to run:\n",
      "\n",
      "python Build_GeoTiff_From_Geogrid_File.py \\\n",
      "\t -i /home/docker/GIS_Training/Croton_Lambert/geo_em.d01.nc \\\n",
      "\t -v HGT_M \\\n",
      "\t -o /home/docker/GIS_Training/Outputs/HGT_M.tif\n",
      "\n",
      "Script initiated at Sun Nov  1 14:38:35 2020\n",
      "Using default variable name: HGT_M\n",
      "Input WPS Geogrid or Fulldom file: /home/docker/GIS_Training/Croton_Lambert/geo_em.d01.nc\n",
      "Input netCDF variable name: HGT_M\n",
      "Output raster file: /home/docker/GIS_Training/Outputs/HGT_M.tif\n",
      "WPS netCDF projection identification initiated...\n",
      "    Map Projection: Lambert Conformal Conic\n",
      "    Using MOAD_CEN_LAT for latitude of origin.\n",
      "    Using Standard Parallel 2 in Lambert Conformal Conic map projection.\n",
      "    Geo-referencing step completed without error in  0.05 seconds.\n",
      "    X-dimension: 'west_east'.\n",
      "    Y-dimension: 'south_north'.\n",
      "    Reversing order of dimension 'south_north'\n",
      "    Time dimension found: 'Time'.\n",
      "      Time dimension size = 1.\n",
      "    Dimensions and indices or slices on those dimensions:\n",
      "        Time: 0\n",
      "        south_north: slice(None, None, -1)\n",
      "        west_east: slice(None, None, None)\n",
      "    Size of array being sent to raster: (16, 15)\n",
      "    GDAL Data type derived from input array: 6 (float32)\n",
      "    Bands in output raster: 1\n",
      "    Created GTiff format raster from HGT_M variable: /home/docker/GIS_Training/Outputs/HGT_M.tif\n",
      "Process complted in 0.09 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Define the variable to export to raster\n",
    "in_var = \"HGT_M\"\n",
    "\n",
    "# Define the output raster file using variable name defined above\n",
    "out_file = os.path.join(output_folder, f'{in_var}.tif')\n",
    "\n",
    "# Print information to screen for reference\n",
    "print('Command to run:\\n')\n",
    "print('python Build_GeoTiff_From_Geogrid_File.py \\\\\\n\\t -i {0} \\\\\\n\\t -v {1} \\\\\\n\\t -o {2}\\n'.format(in_geogrid, in_var, out_file))\n",
    "\n",
    "# Run the script with required parameters\n",
    "! python Build_GeoTiff_From_Geogrid_File.py -i {in_geogrid} -v {in_var} -o {out_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View outputs\n",
    "Now that the tool has completed, we want to take a look at the output. We will create another interactive map and load the data as a layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7979489160b54cd4a2f1b1e55256c506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[41.47099335461109, -73.74365046255139], controls=(ZoomControl(options=['position', 'zoom_in_text',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import third-party visualization libraries\n",
    "import rasterio\n",
    "from matplotlib import pyplot\n",
    "from osgeo import gdal\n",
    "from ipyleaflet import ImageOverlay\n",
    "from jupyter_functions import cmap_options, show_raster_map\n",
    "\n",
    "# Create a map object from pre-build function\n",
    "m2 = create_map(map_center, 10)\n",
    "\n",
    "# Render the map\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use pre-built function to render the GeoTiff on the map, already warped to the map's coordinate system\n",
    "show_raster_map(out_file, m2, b_shp, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You will see the elevation grid applied to the map. This grid is 1km, so there is not much detail, but it is still useful to see if the topographic features are in the correct geographic locations according to the basemap. Also, there is no color-ramp for reference. This is a limitation of using the web browser over a GIS application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the hydrologic routing grids, aka the \"routing stack\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The tool `Build_Routing_Stack.py` script is a program to build the full set of hydrologically-processed routing grids and additional data required by WRF-Hydro. This is the main utility for performing WRF-Hydro GIS pre-processing. The required inputs are related to the domain, routing grid resolution, and other options and parameter values. The output will be a routing stack zip file with WRF-Hydro domain and parameter files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â€¢ Required Parameters:<br>\n",
    "&emsp;`-i` -WRF/WPS GEOGRID file (geo_em.d0*.nc)<br>\n",
    "&emsp;`-d` -High-resolution Elevation raster file (Esri GRID, GeoTIFF, VRT, etc.)<br>\n",
    "&emsp;`-R` -Regridding Factor â€“ nesting relationship of routing:land surface model grid cells<br>\n",
    "&emsp;`-t` -Minimum basin area threshold (in routing grid cells)<br>\n",
    "&emsp;`-o` -Output ZIP File containing all script outputs<br>\n",
    "\n",
    "â€¢ Optional Parameters:<br>\n",
    "&emsp;`--CSV` -Station Locations location file (.csv)<br>\n",
    "&emsp;`-b` -Option to mask channel grids not contributing to provided station locations<br>\n",
    "&emsp;`-r` -Reach based (Muskingum / Muskingum-Cunge) routing option<br>\n",
    "&emsp;`-l` -Lake Polygons (polygon feature class or .shp)<br>\n",
    "&emsp;`-O` -OVROUGHRTFAC â€“ Multiplier on Manning's roughness for overland flow. default=1.0<br>\n",
    "&emsp;`-T` -RETDEPRTFAC â€“ Multiplier on maximum retention depth before flow is routed as overland flow. default=1.0<br>\n",
    "&emsp;-LKSATFAC â€“ (script global variable) Multiplier on saturated hydraulic conductivity in lateral flow direction. default=1000.0<br>\n",
    "&emsp;`--starts` -Path to point shapefile or feature class containing channel initiation locations (overrides `-t` parameter)<br>\n",
    "&emsp;`--gw` -Path to polygon shapefile or feature class containing prescribed groundwater basin locations<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request help message from the script\n",
    "This tool has many different parameters and possible configurations. Using the command line, we can take a look at the different arguements that can be used, if they are required or optional, and what their default values are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script initiated at Sun Nov  1 14:38:37 2020\n",
      "usage: Build_Routing_Stack.py [-h] -i IN_GEOGRID [--CSV IN_CSV]\n",
      "                              [-b BASIN_MASK] [-r RB_ROUTING]\n",
      "                              [-l IN_RESERVOIRS] -d INDEM [-R CELLSIZE]\n",
      "                              [-t THRESHOLD] [-o OUT_ZIP_FILE]\n",
      "                              [-O OVROUGHRTFAC_VAL] [-T RETDEPRTFAC_VAL]\n",
      "                              [--starts CHANNEL_STARTS] [--gw GW_POLYS]\n",
      "\n",
      "This is a program to perform the full routing-stack GIS pre-processingfor WRF-\n",
      "Hydro. The inputs will be related to the domain, the desired routing nest\n",
      "factor, and other options and parameter values. The output will be a routing\n",
      "stack zip file with WRF-Hydro domain and parameter files.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -i IN_GEOGRID         Path to WPS geogrid (geo_em.d0*.nc) file [REQUIRED]\n",
      "  --CSV IN_CSV          Path to input forecast point CSV file [OPTIONAL]\n",
      "  -b BASIN_MASK         Mask CHANNELGRID variable to forecast basins?\n",
      "                        [True/False]. default=False\n",
      "  -r RB_ROUTING         Create reach-based routing (RouteLink) files?\n",
      "                        [True/False]. default=False\n",
      "  -l IN_RESERVOIRS      Path to reservoirs shapefile or feature class\n",
      "                        [OPTIONAL]. If -l is TRUE, this is required.\n",
      "  -d INDEM              Path to input high-resolution elevation raster\n",
      "                        [REQUIRED]\n",
      "  -R CELLSIZE           Regridding (nest) Factor. default=10\n",
      "  -t THRESHOLD          Number of routing grid cells to define stream.\n",
      "                        default=200\n",
      "  -o OUT_ZIP_FILE       Output routing stack ZIP file\n",
      "  -O OVROUGHRTFAC_VAL   OVROUGHRTFAC value. default=1.0\n",
      "  -T RETDEPRTFAC_VAL    RETDEPRTFAC value. default=1.0\n",
      "  --starts CHANNEL_STARTS\n",
      "                        Path to channel initiation points feature class. Must\n",
      "                        be 2D point type. [OPTIONAL]\n",
      "  --gw GW_POLYS         Path to groundwater polygons feature class [OPTIONAL]\n"
     ]
    }
   ],
   "source": [
    "! python Build_Routing_Stack.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Execute the script using command-line syntax\n",
    "We will begin by assigning file paths to variables, then use those variables in the command line tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command to run:\n",
      "\n",
      "python Build_Routing_Stack.py \\\n",
      "\t -i /home/docker/GIS_Training/Croton_Lambert/geo_em.d01.nc \\\n",
      "\t -l /home/docker/GIS_Training/Croton_Lambert/lake_shapes/lakes.shp \\\n",
      "\t --CSV /home/docker/GIS_Training/Croton_Lambert/croton_frxst_pts_FOSS.csv \\\n",
      "\t -d /home/docker/GIS_Training/Croton_Lambert/NED_30m_Croton.tif \\\n",
      "\t -R 4 \\\n",
      "\t -t 20 \\\n",
      "\t -o /home/docker/GIS_Training/Outputs/croton_test.zip\n",
      "\n",
      "Script initiated at Sun Nov  1 14:38:38 2020\n",
      "  Parameter values that have not been altered from script default values:\n",
      "    Using default basin mask setting: False\n",
      "    Using default reach-based routing setting: False\n",
      "    Using default OVROUGHRTFAC parameter value: 1.0\n",
      "    Using default RETDEPRTFAC parameter value: 1.0\n",
      "  Values that will be used in building this routing stack:\n",
      "    Input WPS Geogrid file: /home/docker/GIS_Training/Croton_Lambert/geo_em.d01.nc\n",
      "    Forecast Point CSV file: /home/docker/GIS_Training/Croton_Lambert/croton_frxst_pts_FOSS.csv\n",
      "    Mask CHANNELGRID variable to forecast basins?: False\n",
      "    Create reach-based routing (RouteLink) files?: False\n",
      "    Lake polygon feature class: /home/docker/GIS_Training/Croton_Lambert/lake_shapes/lakes.shp\n",
      "    Input high-resolution DEM: /home/docker/GIS_Training/Croton_Lambert/NED_30m_Croton.tif\n",
      "    Regridding factor: 4\n",
      "    Stream initiation threshold: 20\n",
      "    OVROUGHRTFAC parameter value: 1.0\n",
      "    RETDEPRTFAC parameter value: 1.0\n",
      "    Input channel initiation start point feature class: None\n",
      "    Input groundwater basin polygons: None\n",
      "    Output ZIP file: /home/docker/GIS_Training/Outputs/croton_test.zip\n",
      "  Running Process GEOGRID function\n",
      "    Forecast points provided.\n",
      "  Reach-based routing files will not be created.\n",
      "WPS netCDF projection identification initiated...\n",
      "    Map Projection: Lambert Conformal Conic\n",
      "    Using MOAD_CEN_LAT for latitude of origin.\n",
      "    Using Standard Parallel 2 in Lambert Conformal Conic map projection.\n",
      "    Geo-referencing step completed without error in  0.04 seconds.\n",
      "  Building sub-grid of model grid.\n",
      "    Original grid spacing dx=1000.0, dy=-1000.0\n",
      "    Original grid size: rows=16, cols=15\n",
      "    New grid spacing: dx=250.0, dy=-250.0\n",
      "    New dimensions: rows=64, cols=60\n",
      "    Created projection definition from input NetCDF GEOGRID file.\n",
      "    Proj4: +proj=lcc +lat_0=41.4710083007812 +lon_0=-97 +lat_1=30 +lat_2=60 +x_0=0 +y_0=0 +R=6370000 +units=m +no_defs\n",
      "    Coarse grid GeoTransform: 1841999.0194101864 1000.0 0 278495.814356732 0 -1000.0\n",
      "    Coarse grid extent [Xmin, Ymin, Xmax, Ymax]: [1841999.0194101864, 262495.814356732, 1856999.0194101864, 278495.814356732]\n",
      "    Fine grid extent [Xmin, Ymin, Xmax, Ymax]:   [1841999.0194101864, 262495.814356732, 1856999.0194101864, 278495.814356732]\n",
      "    GDAL Data type derived from input array: 6 (float32)\n",
      "  Creating CF-netCDF File.\n",
      "    Esri PE String: PROJCS[\"unnamed\",GEOGCS[\"GCS_Sphere\",DATUM[\"D_Sphere\",SPHEROID[\"unnamed\",6370000.0,0.0]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Lambert_Conformal_Conic\"],PARAMETER[\"False_Easting\",0.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",-97.0],PARAMETER[\"Standard_Parallel_1\",30.0],PARAMETER[\"Standard_Parallel_2\",60.0],PARAMETER[\"Latitude_Of_Origin\",41.4710083007812],UNIT[\"Meter\",1.0]]\n",
      "    Map Projection of input raster : lambert_conformal_conic\n",
      "    Starting Process: Building to XMap/YMap\n",
      "    Conversion of input raster to XMap/YMap completed without error.\n",
      "  netCDF global attributes set after  0.01 seconds.\n",
      "    Raster resampling initiated...\n",
      "    The High-resolution dataset will be 250.0m\n",
      "    Projected input raster to model grid in  0.14 seconds.\n",
      "  Deriving geocentric coordinates on routing grid from bilinear interpolation of geogrid coordinates.\n",
      "    GDAL Data type derived from input array: 6 (float32)\n",
      "    GDAL Data type derived from input array: 6 (float32)\n",
      "    Raster resampling initiated...\n",
      "    The High-resolution dataset will be 250.0m\n",
      "    Projected input raster to model grid in  0.02 seconds.\n",
      "    Raster resampling initiated...\n",
      "    The High-resolution dataset will be 250.0m\n",
      "    Projected input raster to model grid in  0.02 seconds.\n",
      "  Creating CF-netCDF File.\n",
      "    Esri PE String: PROJCS[\"unnamed\",GEOGCS[\"GCS_Sphere\",DATUM[\"D_Sphere\",SPHEROID[\"unnamed\",6370000.0,0.0]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Lambert_Conformal_Conic\"],PARAMETER[\"False_Easting\",0.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",-97.0],PARAMETER[\"Standard_Parallel_1\",30.0],PARAMETER[\"Standard_Parallel_2\",60.0],PARAMETER[\"Latitude_Of_Origin\",41.4710083007812],UNIT[\"Meter\",1.0]]\n",
      "    Map Projection of input raster : lambert_conformal_conic\n",
      "    Starting Process: Building to XMap/YMap\n",
      "    Conversion of input raster to XMap/YMap completed without error.\n",
      "    Proceeding to add LATITUDE and LONGITUDE variables after     0.01 seconds.\n",
      "  netCDF global attributes set after  0.01 seconds.\n",
      "    Raster resampling initiated...\n",
      "    The High-resolution dataset will be 250.0m\n",
      "    Projected input raster to model grid in  0.02 seconds.\n",
      "    Process: landuse written to output netCDF.\n",
      "Terrain processing step initiated...\n",
      "    Using WhiteboxTools v1.4.0 by Dr. John B. Lindsay (c) 2017-2020\n",
      "    Depression Filling algorithm: Whitebox Fill Depressions.\n",
      "    Process: TOPOGRAPHY written to output netCDF.\n",
      "    Coerced 21 0-value flow direction cells to flow off of the grid.\n",
      "    Process: FLOWDIRECTION written to output netCDF.\n",
      "    Process: FLOWACC written to output netCDF.\n",
      "    Flow accumulation will be thresholded to build channel pixels.\n",
      "    Process: CHANNELGRID written to output netCDF.\n",
      "    Process: STREAMORDER written to output netCDF.\n",
      "    Process: RETDEPRTFAC written to output netCDF.\n",
      "    Process: OVROUGHRTFAC written to output netCDF.\n",
      "    Process: LKSATFAC written to output netCDF.\n",
      "Terrain processing step completed without error in  0.05 seconds.\n",
      "    Forecast points provided and basins being delineated.\n",
      "    Process: frxst_pts written to output netCDF.\n",
      "    Process: basn_msk written to output netCDF.\n",
      "    Channelgrid will not be masked to basins.\n",
      "    Built forecast point outputs in  0.12 seconds.\n",
      "    Reservoir polygons provided. Lake routing will be activated.\n",
      "      MEMORY driver is available.\n",
      "  Done producing output vector polygon shapefile in  0.00 seconds\n",
      "    Input shapefile projection does not match requested output. Transforming.\n",
      "    Number of output features: 1 of 1\n",
      "  Completed reprojection and-or clipping in 0.16 seconds.\n",
      "    Adding auto-incremented lake ID field (1...n)\n",
      "    Starting to gather lake centroid and area information.\n",
      "    Done gathering lake centroid information.\n",
      "    Found 1 lakes on active channels. Lost 0 lakes that were not on active channels.\n",
      "    Removing lakes not on gridded channel network\n",
      "    Process: LAKEGRID written to output netCDF.\n",
      "    Process: CHANNELGRID written to output netCDF.\n",
      "    Starting to create lake parameter table.\n",
      "        Lakes Table: 1 Lakes\n",
      "        Starting to fill in lake parameter table NC file.\n",
      "        Done writing LAKEPARM.nc table to disk.\n",
      "    Lake parameter table created without error in  0.32 seconds.\n",
      "Beginning to build 2D groundwater basin inputs\n",
      "  Building groundwater inputs using FullDom LINKID local basins\n",
      "    Generating LINKID grid for building local sub-basins.\n",
      "Finished building fine-grid groundwater basin grids in  0.02 seconds\n",
      "Beginning to build coarse-grid groundwater basins and parameters\n",
      "    Found 72 basins in the watershed grid\n",
      "    Raster resampling initiated...\n",
      "    The High-resolution dataset will be 1000.0m\n",
      "    Projected input raster to model grid in  0.02 seconds.\n",
      "    Found 69 basins (potentially including nodata values) in the file after resampling to the coarse grid.\n",
      "    GDAL Data type derived from input array: 5 (int32)\n",
      "  Creating CF-netCDF File.\n",
      "    Esri PE String: PROJCS[\"unnamed\",GEOGCS[\"GCS_Sphere\",DATUM[\"D_Sphere\",SPHEROID[\"unnamed\",6370000.0,0.0]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Lambert_Conformal_Conic\"],PARAMETER[\"False_Easting\",0.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",-97.0],PARAMETER[\"Standard_Parallel_1\",30.0],PARAMETER[\"Standard_Parallel_2\",60.0],PARAMETER[\"Latitude_Of_Origin\",41.4710083007812],UNIT[\"Meter\",1.0]]\n",
      "    Map Projection of input raster : lambert_conformal_conic\n",
      "    Starting Process: Building to XMap/YMap\n",
      "    Conversion of input raster to XMap/YMap completed without error.\n",
      "  netCDF global attributes set after  0.01 seconds.\n",
      "    NC dimensions: 16, 15\n",
      "    GWBUCKS array dimensions: 16, 15\n",
      "    Process: /home/docker/GIS_Training/Outputs/scratchdir/GWBASINS.nc completed without error\n",
      "    Finished building groundwater grid file in  0.01 seconds\n",
      "    Calculating size and ID parameters for basin polygons.\n",
      "    Created output bucket parameter table (.nc): /home/docker/GIS_Training/Outputs/scratchdir/GWBUCKPARM.nc.\n",
      "  Finished building groundwater bucket parameter table in  0.00 seconds.\n",
      "Finished building groundwater parameter files in  0.03 seconds\n",
      "Built output .zip file in  0.85 seconds.\n",
      "Process completed in 0.85 seconds.\n"
     ]
    }
   ],
   "source": [
    "import Build_Routing_Stack\n",
    "\n",
    "# Define script input parameters using python variables\n",
    "in_geogrid = os.path.join(data_folder, 'geo_em.d01.nc')\n",
    "lakes = os.path.join(data_folder, 'lake_shapes', 'lakes.shp')\n",
    "csv = os.path.join(data_folder, 'croton_frxst_pts_FOSS.csv')\n",
    "in_dem = os.path.join(data_folder, 'NED_30m_Croton.tif')\n",
    "regrid_factor = 4\n",
    "routing_cells = 20\n",
    "out_zip = os.path.join(output_folder, 'croton_test.zip')\n",
    "\n",
    "# Print information to screen for reference\n",
    "print('Command to run:\\n')\n",
    "print('python Build_Routing_Stack.py \\\\\\n\\t -i {0} \\\\\\n\\t -l {1} \\\\\\n\\t --CSV {2} \\\\\\n\\t -d {3} \\\\\\n\\t -R {4} \\\\\\n\\t -t {5} \\\\\\n\\t -o {6}\\n'.format(in_geogrid, lakes, csv, in_dem, regrid_factor, routing_cells, out_zip))\n",
    "\n",
    "# Run the script with required parameters\n",
    "! python Build_Routing_Stack.py -i {in_geogrid} -l {lakes} --CSV {csv} -d {in_dem} -R {regrid_factor} -t {routing_cells} -o {out_zip}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Understanding the outputs\n",
    "\n",
    "The `Build_Routing_Stack.py` script creates a Zip archive of output files according to the options provided to the tool. There will be at least four netCDF files; one spatial metadata file describing the LDAS grid (â€˜GEOGRID_LDASOUT_Spatial_Metadata.nc), one 2D file describing the routing grid (â€˜Fulldom_hires.ncâ€™), a 2D groundwater basin file (â€˜GWBASINS.ncâ€™), and a 1D groundwater basin parameter file (â€˜GWBUCKPARM.ncâ€™). The â€˜Fulldom_hires.ncâ€™ file will contain between 13 and 14 2-dimensional (gridded) netCDF variables. The output Zip file may additionally include shapefiles (.shp and accompanying files) describing the geometry of modeled lakes or the vector stream network, and netCDF 1-dimensional parameter tables (.nc) describing lake parameters (â€˜LAKEPARM.ncâ€™) or the stream network (â€˜Route_Link.ncâ€™). All variables in the â€˜Fulldom_hires.ncâ€™ file will have the same grid dimensions. The x-dimension is always â€˜xâ€™ and the y-dimension always â€˜yâ€™.  Below is an alphabetically sorted list of gridded variables that are created by the `Build_Routing_Stack.py` tool, and Table 5 contains descriptions of each grid.\n",
    "\n",
    "Fulldom_hires.nc file:\n",
    "  + CHANNELGRID - The channel grid. Channel pixels = 0, non-channel pixels = -9999. If the `-b` option is set to TRUE, the output will be masked to the gaged basins provided, where non-gaged channels are given a value of â€˜-1â€™. If lake routing is activated, lake outflow points will be identified by the lake ID value.\n",
    "  + FLOWACC â€“ Flow accumulation grid. This grid gives the number of contributing cells for each cell in the domain. This grid is provided for convenience and is not read by WRF-Hydro.\n",
    "  + FLOWDIRECTION â€“ Flow direction grid. This grid gives the direction of flow using the D8 algorithm between each cell and the steepest downslope neighbor according to Jenson and Domingue (1988). The result is an integer grid with values ranging from 1 to 128.\n",
    "  + frxst_pts â€“ Gage location grid. If a forecast point CSV file is provided, the grid will have a cell identified at the location of each forecast point (gage) in the gage CSV file. If no input CSV gage location file is provided, this grid will be uniform with values of â€˜-9999â€™. Gage pixels are numbered in the same way as the â€˜basn_mskâ€™ grid. NoData cells are given a value of â€˜-9999â€™.\n",
    "  + basn_msk â€“ Forecast basins grid. If a CSV gage location file is provided, catchments are delineated from a point that is up to 3 pixels downstream of the gage coordinates. This distance can be modified by altering the â€˜walkerâ€™ global variable in the â€˜wrfhydro_functions.pyâ€™ script. If masking of the â€˜CHANNELGRIDâ€™ is selected, this layer is the mask. Basins are numbered according to the values in the â€˜FIDâ€™ field of the input gage CSV file. If no gage location file is provided, this grid will be uniform with values of â€˜-9999â€™.\n",
    "  + LAKEGRID â€“ The lake grid. If a lake polygon shapefile is provided to the `-l` parameter, this grid will contain ID values for each lake that can be resolved on the routing grid. Otherwise, this grid will be uniform with values of -9999.\n",
    "  + landuse â€“ This is the same data as the â€˜LU_INDEXâ€™ variable in the GEOGRID file, but resampled using Nearest Neighbor assignment to the resolution of the routing grid. This grid is provided for convenience and is not read by WRF-Hydro.\n",
    "  + LATITUDE â€“ Grid of the latitude at the center of each grid cell, in a geographic coordinate system (WGS84).\n",
    "  + LINKID â€“ The channel ID grid. This grid provides a unique integer identifier for each channel segment that is defined in the â€˜linkâ€™ variable of the â€˜Route_Link.ncâ€™ file and the â€˜STRM_VALâ€™ field in the â€˜streams.shpâ€™ shapefile. The â€˜LINKIDâ€™ grid will only be created if the option `-r` is TRUE.\n",
    "  + LONGITUDE â€“ Grid of longitude value at the center of each grid cell, in a geographic coordinate system (WGS84).\n",
    "  + OVROUGHRTFAC â€“ OVROUGHRTFAC parameter. Currently set to a default of 1.0. This default value may be changed by providing an alternate value to the `-O` parameter.\n",
    "  + RETDEPRTFAC â€“ RETDEPRTFAC (retention depth multiplier) parameter. Currently set to a default of 1.0. This default value may be changed by providing an alternate value `-T` parameter.\n",
    "  + STREAMORDER â€“ Stream order grid, calculated using the Strahler method (Strahler 1957).\n",
    "  + TOPOGRAPHY â€“ Elevation grid. The units of elevation are the same as the input elevation raster dataset (`-d INDEM`), which should be specified in meters (m) above sea level (ASL). This grid is derived from the elevation values in the input elevation raster, but has been resampled to the routing grid resolution, and pit-filled according to the method described in Planchon and Darboux (2002).\n",
    "\n",
    "Other files:\n",
    "  + GEOGRID_LDASOUT_Spatial_Metadata.nc  - This is a CF-netCDF format file that provides the spatial metadata associated with the GEOGRID variables. By default, no 2-dimensional grids are written to the file. This file may be used by WRF-Hydro for appending geospatial metadata to the land surface model output, if necessary.\n",
    "  + GWBASINS.nc - This is a 2D netCDF file of the location of groundwater basins, regridded to the LSM grid resolution. NoData cells are given a value of â€˜-9999â€™. This file is by default created using the â€˜FullDom LINKID local basinsâ€™ method of defining groundwater basins.\n",
    "  + LAKEPARM.nc â€“ Lake parameter table. This 1D netCDF format file is created if a lake shapefile is provided as input to the `-l` parameter. The table will contain a record for each lake feature in the + Fulldom_hires.nc â€˜LAKEGRIDâ€™ variable, and contain derived and default parameters for each lake.\n",
    "  + Route_Link.nc â€“ The reach-based routing parameter file. This 1D netCDF format file is created if the `-r` parameter is TRUE. The file contains a record for each stream segment. The stream segments in this table are also identified by the unique â€˜LINKIDâ€™ values in the â€˜LINKIDâ€™ variable in the â€˜Fulldom_hires.ncâ€™ file, and values in the â€˜STRM_VALâ€™ field of the output â€˜streams.shpâ€™ shapefile. This table contains derived and default stream segment parameters that are calculated based on the vector stream network and topology in the â€˜streams.shpâ€™ shapefile.\n",
    "  + streams.* (ancillary) - Streams shapefile, containing one feature for each stream segment in the domain. This file is meant to accompany the â€˜Route_Link.ncâ€™ reach-based routing parameter file and Fulldom_hires.nc â€˜LINKIDâ€™ variable. The â€˜streamsâ€™ shapefile is only created when the option `-l` is used. The â€˜STRM_VALâ€™ field is the unique identifier for each stream segment, and corresponds to the â€˜linkâ€™ variable of the â€˜Route_Link.ncâ€™ file and the â€˜LINKIDâ€™ variable in the â€˜Fulldom_hires.ncâ€™ file. The geometry of the stream segments in this shapefile informs many of the parameters in the â€˜Route_Link.ncâ€™ file.\n",
    "  + lakes.* (ancillary) - Lakes shapefile, containing one feature for each reservoir in the simulation domain. This file is meant to accopmany the 'LAKEPARM.nc' reservoir parameter file. If `-r TRUE` is used, then Fulldom_hires.nc 'LAKEID' variable will contain -9999 values only. The geometry of reservoir objects informs many of the parameters in 'LAKEPARM.nc' file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Examine outputs of GIS pre-processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The tool `Examine_Outputs_of_GIS_Preprocessor.py` script is a tool that takes the output ZIP file generated using the Process Geogrid script (executed above) and creates a raster from each 2D variable in each WRF-Hydro input netCDF file. In addition, other data will be extracted such as any shapefiles, 1D netCDF tables, etc. The input to the tool should be a .zip file that was created using the WRF Hydro pre-processing tools. The tool will create the output folder if it does not already exist, and write all results to that location.\n",
    "\n",
    "#### Request help message from the script\n",
    "This tool has a single input and single output parameter. Using the command line, we can take a look at the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script initiated at Sun Nov  1 14:38:40 2020\n",
      "usage: Examine_Outputs_of_GIS_Preprocessor.py [-h] -i IN_ZIP -o OUT_FOLDER\n",
      "\n",
      "This tool takes the output zip file from the ProcessGeogrid script and creates\n",
      "a raster from each output NetCDF file. The Input should be a .zip file that\n",
      "was created using theWRF Hydro pre-processing tools. The tool will create the\n",
      "folder which will contain theresults (out_folder), if that folder does not\n",
      "already exist.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help     show this help message and exit\n",
      "  -i IN_ZIP      Path to WRF Hydro routing grids zip file.\n",
      "  -o OUT_FOLDER  Path to output folder.\n"
     ]
    }
   ],
   "source": [
    "! python Examine_Outputs_of_GIS_Preprocessor.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Execute the script using command-line syntax\n",
    "We will define the output directory for the tool to create, then use defined variables to execute the command line tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command to run:\n",
      "\n",
      "python Examine_Outputs_of_GIS_Preprocessor.py \\\n",
      "\t -i /home/docker/GIS_Training/Outputs/croton_test.zip \\\n",
      "\t -o /home/docker/GIS_Training/Outputs/Raster_Outputs\n",
      "\n",
      "Script initiated at Mon Nov  2 05:40:43 2020\n",
      "Requested output directory already exists. \n",
      "Please specify a non-existant directory as output.\n"
     ]
    }
   ],
   "source": [
    "# Define output directory to store GeoTiff output of all routing stack grids\n",
    "raster_outputs = os.path.join(output_folder, \"Raster_Outputs\")\n",
    "\n",
    "# Print information to screen for reference\n",
    "print('Command to run:\\n')\n",
    "print('python Examine_Outputs_of_GIS_Preprocessor.py \\\\\\n\\t -i {0} \\\\\\n\\t -o {1}\\n'.format(out_zip, raster_outputs))\n",
    "\n",
    "# Run the script with required parameters\n",
    "! python Examine_Outputs_of_GIS_Preprocessor.py -i {out_zip} -o {raster_outputs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Vizualize the output grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to take a look at the output rasters. Below, we utilize a Jupyter widget to choose each raster from a drop down menu. Each of the 2D variables in Fulldom_hires.nc (the routing grid netCDF file) will be displayed as a rectangular grid. Take a look at some of the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3792224b514165933bdb127132b0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Variable:', index=3, options=(('Basin', 'BASIN'), ('Basin mask', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.see_raster(x)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "def see_raster(x):\n",
    "    src = rasterio.open(os.path.join(raster_outputs, f\"{x}.tif\"))\n",
    "    cmap, norm = cmap_options(x)\n",
    "    if x in ['TOPOGRAPHY']:\n",
    "        pyplot.imshow(src.read(1), cmap=cmap,  aspect='auto', norm=norm, interpolation='nearest', vmin=0)\n",
    "    else:\n",
    "        pyplot.imshow(src.read(1), cmap=cmap,  aspect='auto', norm=norm, interpolation='nearest')\n",
    "    cbar = pyplot.colorbar()\n",
    "    \n",
    "    # Keep the automatic aspect while scaling the image up in size\n",
    "    fig = pyplot.gcf()\n",
    "    w, h = fig.get_size_inches()\n",
    "    fig.set_size_inches(w * 1.75, h * 1.75)\n",
    "    \n",
    "    # Show image\n",
    "    pyplot.show()\n",
    "\n",
    "in_raster = widgets.Dropdown(\n",
    "    options=[('Basin', 'BASIN'), ('Basin mask', 'basn_msk'), ('Channel grid', 'CHANNELGRID'), ('Flow accumulation', 'FLOWACC'),\n",
    "            ('Flow direction', 'FLOWDIRECTION'), ('Forecast points', 'frxst_pts'), ('Lake grid', 'LAKEGRID'),\n",
    "            ('Land use', 'landuse'), ('Latitude', 'LATITUDE'), ('LKSATFAC', 'LKSATFAC'), ('Longitude', 'LONGITUDE'),\n",
    "            ('OVROUGHRTFAC', 'OVROUGHRTFAC'), ('RETDEPRTFAC', 'RETDEPRTFAC'), ('Stream order', 'STREAMORDER'),\n",
    "            ('Topography', 'TOPOGRAPHY')],\n",
    "    value='FLOWACC',\n",
    "    description='Variable:')\n",
    "\n",
    "interact(see_raster, x=in_raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the raster data projected onto a map. Use the dropdown widget below the map to add rasters as layers to the map. Use the menu in the top right corner of the map to turn layers on and off. Behind the scenes, each model grid is being reprojected to Web Mercator for overlay on a WMS basemap for some interactivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb93815ac8884c9f9f063889c40a53bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[41.47099335461109, -73.74365046255139], controls=(ZoomControl(options=['position', 'zoom_in_text',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a map object from pre-build function\n",
    "m3 = create_map(map_center, 10)\n",
    "\n",
    "# Render the map\n",
    "m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12211a63a42144bfbeb36c3bea39a935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Variable:', index=2, options=(('Basin', 'BASIN'), ('Flow accumulatâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f(x)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    r_path = os.path.join(raster_outputs, f\"{x}.tif\")\n",
    "    show_raster_map(r_path, m3, b_shp, output_folder)\n",
    "\n",
    "in_raster = widgets.Dropdown(\n",
    "    options=[('Basin', 'BASIN'), ('Flow accumulation', 'FLOWACC'), ('Flow direction', 'FLOWDIRECTION'), \n",
    "             ('Land use', 'landuse'), ('Stream order', 'STREAMORDER'), ('Topography', 'TOPOGRAPHY')],\n",
    "    value='FLOWDIRECTION',\n",
    "    description='Variable:',\n",
    ")\n",
    "interact(f, x=in_raster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
